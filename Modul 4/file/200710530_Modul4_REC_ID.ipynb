{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pba-modul4-id-text-similarity-clustering-recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "import modSpellChecker_1 as sc\n",
    "from contractions_1 import CONTRACTION_MAP\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deklarasi Fungsi untuk Normalisasi Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "character = ['z','y','x','w','v','u','t','s','r','q','p','o','n','m','l','k','j','i','h','g','f','e','d',',',';',':','-','...','?','!', '(',')','[',']','{','}','<','>', '\"','/','\\'','#','-','@']\n",
    "\n",
    "def repeatcharNormalize(text):\n",
    "    for i in range(len(character)):\n",
    "        charac_long = 5\n",
    "        while charac_long >= 2:\n",
    "            char = character[i] * charac_long\n",
    "            text = text.replace(char, character[i])\n",
    "            charac_long -= 1\n",
    "    return text\n",
    "\n",
    "def spellNormalize(text):\n",
    "    spellCheck = []\n",
    "    for i in text:\n",
    "        if i not in character:\n",
    "            j = sc.correction(i)\n",
    "            spellCheck.append(j)\n",
    "        else:\n",
    "            spellCheck.append(i)\n",
    "    return spellCheck\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def expand_contractions(text, contraction_mapping):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())\n",
    "        expanded_contraction = first_char + expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "def stemmer_text(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    filtered_tokens = filter(None, [pattern.sub('',token) for token in tokens])\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StopWordRemoverFactory()\n",
    "stopword_list = factory.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, tokenize=False):\n",
    "    normalized_corpus = []\n",
    "    for text in corpus:\n",
    "        text = expand_contractions(text, CONTRACTION_MAP)\n",
    "        text = stemmer_text(text)\n",
    "        text = remove_special_characters(text)\n",
    "        text = repeatcharNormalize(text)\n",
    "        text = remove_stopwords(text)\n",
    "        normalized_corpus.append(text)\n",
    "        if tokenize:\n",
    "            text = tokenize_text(text)\n",
    "            text = spellNormalize(text)\n",
    "            normalized_corpus.append(text)\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penyiapan Data Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Judul</th>\n",
       "      <th>Artikel</th>\n",
       "      <th>Jenis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rupiah masih rawan bergejolak</td>\n",
       "      <td>Nilai tukar rupiah terhadap dolar Amerika Seri...</td>\n",
       "      <td>ekonomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRC sasar ritel tradisional jadi pilar ekonomi...</td>\n",
       "      <td>Perkembangan teknologi telah menyebabkan perub...</td>\n",
       "      <td>ekonomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kiat memaksimalkan Facebook untuk bisnis</td>\n",
       "      <td>Media sosial kini bukan hanya menjadi alat unt...</td>\n",
       "      <td>ekonomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kiat menambah relasi bisnis</td>\n",
       "      <td>Dalam menjalankan bisnis, menjalin relasi puny...</td>\n",
       "      <td>ekonomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prinsip dasar merintis bisnis</td>\n",
       "      <td>Merintis usaha memang bukan pekerjaan mudah. A...</td>\n",
       "      <td>ekonomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Genoa 1 - 1 Sampdoria - Liga Serie A 2018/2019</td>\n",
       "      <td>Genoa dan Sampdoria sama-sama gagal memetik po...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>Villarreal 2 - 1 Real Betis - La Liga 2018/2019</td>\n",
       "      <td>Villarreal menjaga langkah untuk mendekatkan d...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>PSM kembali ke puncak klasemen, Persib resmi t...</td>\n",
       "      <td>Persija Jakarta harus rela kembali ke peringka...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Hasil imbang yang pahit bagi AC Milan</td>\n",
       "      <td>\"Hasil imbang yang pahit.\" Begitu laman resmi ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>Seruan untuk Edy Rahmayadi di balik kegagalan ...</td>\n",
       "      <td>Timnas Indonesia mengakhiri babak grup Piala A...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Judul  \\\n",
       "0                         Rupiah masih rawan bergejolak   \n",
       "1     SRC sasar ritel tradisional jadi pilar ekonomi...   \n",
       "2              Kiat memaksimalkan Facebook untuk bisnis   \n",
       "3                           Kiat menambah relasi bisnis   \n",
       "4                         Prinsip dasar merintis bisnis   \n",
       "...                                                 ...   \n",
       "1304     Genoa 1 - 1 Sampdoria - Liga Serie A 2018/2019   \n",
       "1305    Villarreal 2 - 1 Real Betis - La Liga 2018/2019   \n",
       "1306  PSM kembali ke puncak klasemen, Persib resmi t...   \n",
       "1307              Hasil imbang yang pahit bagi AC Milan   \n",
       "1308  Seruan untuk Edy Rahmayadi di balik kegagalan ...   \n",
       "\n",
       "                                                Artikel    Jenis  \n",
       "0     Nilai tukar rupiah terhadap dolar Amerika Seri...  ekonomi  \n",
       "1     Perkembangan teknologi telah menyebabkan perub...  ekonomi  \n",
       "2     Media sosial kini bukan hanya menjadi alat unt...  ekonomi  \n",
       "3     Dalam menjalankan bisnis, menjalin relasi puny...  ekonomi  \n",
       "4     Merintis usaha memang bukan pekerjaan mudah. A...  ekonomi  \n",
       "...                                                 ...      ...  \n",
       "1304  Genoa dan Sampdoria sama-sama gagal memetik po...    sport  \n",
       "1305  Villarreal menjaga langkah untuk mendekatkan d...    sport  \n",
       "1306  Persija Jakarta harus rela kembali ke peringka...    sport  \n",
       "1307  \"Hasil imbang yang pahit.\" Begitu laman resmi ...    sport  \n",
       "1308  Timnas Indonesia mengakhiri babak grup Piala A...    sport  \n",
       "\n",
       "[1309 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataartikel_1.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dataset.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        Rupiah masih rawan bergejolak\n",
       "1    SRC sasar ritel tradisional jadi pilar ekonomi...\n",
       "2             Kiat memaksimalkan Facebook untuk bisnis\n",
       "3                          Kiat menambah relasi bisnis\n",
       "4                        Prinsip dasar merintis bisnis\n",
       "5                       10 Sektor seret pelemahan IHSG\n",
       "6                     8 Sektor perkasa lambungkan IHSG\n",
       "7    Untung rugi ratifikasi tujuh perjanjian dagang...\n",
       "8    Uang muka KPR nol persen untuk PNS pada tahun ...\n",
       "9    Cari untung lewat obligasi negara atau deposit...\n",
       "Name: Judul, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus = normalize_corpus(feature)\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ekstraksi Fitur dengan TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 1716)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 Penghitungan Text Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4.1 Metode Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1299</th>\n",
       "      <th>1300</th>\n",
       "      <th>1301</th>\n",
       "      <th>1302</th>\n",
       "      <th>1303</th>\n",
       "      <th>1304</th>\n",
       "      <th>1305</th>\n",
       "      <th>1306</th>\n",
       "      <th>1307</th>\n",
       "      <th>1308</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333162</td>\n",
       "      <td>0.138819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138819</td>\n",
       "      <td>0.241581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1         2         3         4     5     6     7     8     9     \\\n",
       "0   1.0   0.0  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "1   0.0   1.0  0.000000  0.000000  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "2   0.0   0.0  1.000000  0.333162  0.138819   0.0   0.0   0.0   0.0   0.0   \n",
       "3   0.0   0.0  0.333162  1.000000  0.241581   0.0   0.0   0.0   0.0   0.0   \n",
       "4   0.0   0.0  0.138819  0.241581  1.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   ...  1299  1300  1301  1302  1303  1304  1305  1306  1307  1308  \n",
       "0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1309 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Rupiah masih rawan bergejolak',\n",
       "        'SRC sasar ritel tradisional jadi pilar ekonomi nasional',\n",
       "        'Kiat memaksimalkan Facebook untuk bisnis', ...,\n",
       "        'PSM kembali ke puncak klasemen, Persib resmi tersisih',\n",
       "        'Hasil imbang yang pahit bagi AC Milan',\n",
       "        'Seruan untuk Edy Rahmayadi di balik kegagalan timnas Indonesia'],\n",
       "       dtype=object),\n",
       " (1309,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list = dataset['Judul'].values\n",
    "article_list, article_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_idx = np.where(article_list=='Rupiah masih rawan bergejolak')[0][0]\n",
    "article_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pencarian Dokumen Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_similarities = doc_sim_df.iloc[article_idx].values\n",
    "article_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 44, 766, 603, 760,  40])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_article_idxs = np.argsort(-article_similarities)[1:6]\n",
    "similar_article_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Menjaga kurs rupiah, merawat fundamen ekonomi',\n",
       "       'Pelemahan rupiah belum berpengaruh ke inflasi',\n",
       "       'Pemanfaatan satelit untuk daerah rawan bencana',\n",
       "       'Faktor internal tahan rupiah jatuh lebih dalam',\n",
       "       'Menghadapi gejolak ekonomi global'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_article = article_list[similar_article_idxs]\n",
    "similar_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deklarasi Fungsi untuk Pencarian Dokumen Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_recommender(article_title, articles=article_list,doc_sims=doc_sim_df):\n",
    "    article_idx = np.where(articles == article_title)[0][0]\n",
    "    article_similarities = doc_sims.iloc[article_idx].values\n",
    "    similar_article_idxs = np.argsort(-article_similarities)[1:6]\n",
    "    similar_articles = articles[similar_article_idxs]\n",
    "    return similar_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_articles = ['Rupiah masih rawan bergejolak',\n",
    "'Kiat menambah relasi bisnis',\n",
    "'Hasil imbang yang pahit bagi AC Milan',\n",
    "'SRC sasar ritel tradisional jadi pilar ekonomi nasional',\n",
    "'PSM kembali ke puncak klasemen, Persib resmi tersisih']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Rupiah masih rawan bergejolak\n",
      "Top 5 recommended Article: ['Menjaga kurs rupiah, merawat fundamen ekonomi'\n",
      " 'Pelemahan rupiah belum berpengaruh ke inflasi'\n",
      " 'Pemanfaatan satelit untuk daerah rawan bencana'\n",
      " 'Faktor internal tahan rupiah jatuh lebih dalam'\n",
      " 'Menghadapi gejolak ekonomi global']\n",
      "\n",
      "Article: Kiat menambah relasi bisnis\n",
      "Top 5 recommended Article: ['Kiat rebranding untuk bangkitkan bisnis lesu'\n",
      " \"Kiat merintis bisnis dari ''Filosofi Kopi''\" '7 kiat sukses magang'\n",
      " 'Anggaran dipangkas, target pertumbuhan ditambah'\n",
      " 'Kiat memaksimalkan Facebook untuk bisnis']\n",
      "\n",
      "Article: Hasil imbang yang pahit bagi AC Milan\n",
      "Top 5 recommended Article: ['AC Milan hanya butuh waktu'\n",
      " 'Mahalnya hasil imbang Milan dan laju 7 tim mapan'\n",
      " 'Kecewanya Madrid ditahan imbang Bilbao'\n",
      " 'Inter Milan 1 - 0 Milan - Liga Serie A 2018/2019'\n",
      " 'Kekalahan Milan, kekecewaan Gattuso']\n",
      "\n",
      "Article: SRC sasar ritel tradisional jadi pilar ekonomi nasional\n",
      "Top 5 recommended Article: ['Peran ekonomi kreatif terhadap pertumbuhan ekonomi nasional'\n",
      " 'Pengusaha ritel sayangkan kurangnya koordinasi pemerintah'\n",
      " 'Kampanye di Bogor, Sandiaga janji revitalisasi pasar tradisional'\n",
      " 'Presiden Jokowi Anugerahi 6 Orang Gelar Pahlawan Nasional'\n",
      " 'Ekonomi politik Esemka']\n",
      "\n",
      "Article: PSM kembali ke puncak klasemen, Persib resmi tersisih\n",
      "Top 5 recommended Article: ['Persija ke puncak klasemen, Persib menyerah'\n",
      " 'Persib makin jauh dari puncak klasemen'\n",
      " 'Persib unggul lima angka di puncak klasemen'\n",
      " 'PSM dekati puncak, Persib pilih Balikpapan' 'Persib gagal dekati PSM']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for article in popular_articles:\n",
    "    print('Article:', article)\n",
    "    print('Top 5 recommended Article:',article_recommender(article_title=article))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metode BM25 Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data:\n",
    "-----\n",
    ".. data:: PARAM_K1 - Free smoothing parameter for BM25.\n",
    ".. data:: PARAM_B - Free smoothing parameter for BM25.\n",
    ".. data:: EPSILON - Constant used for negative idf of document in corpus.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "from six import iteritems\n",
    "from six.moves import xrange\n",
    "\n",
    "PARAM_K1 = 2.5\n",
    "PARAM_B = 0.85\n",
    "EPSILON = 0.2\n",
    "\n",
    "class BM25(object):\n",
    "    \"\"\"Implementation of Best Matching 25 ranking function.\n",
    "    Attributes\n",
    "    ----------\n",
    "    corpus_size : int\n",
    "        Size of corpus (number of documents).\n",
    "    avgdl : float\n",
    "        Average length of document in `corpus`.\n",
    "    corpus : list of list of str\n",
    "        Corpus of documents.\n",
    "    f : list of dicts of int\n",
    "        Dictionary with terms frequencies for each document in `corpus`.\n",
    "    df : dict\n",
    "        Dictionary with terms frequencies for whole `corpus`.\n",
    "    idf : dict\n",
    "        Dictionary with inversed terms frequencies for while `corpus`.\n",
    "    doc_len : list of int\n",
    "        List of document lengths.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, corpus):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus : list of list of str\n",
    "            Given corpus.\n",
    "        \"\"\"\n",
    "        self.corpus_size = len(corpus)\n",
    "        self.avgdl = sum(float(len(x)) for x in corpus) / self.corpus_size\n",
    "        self.corpus = corpus\n",
    "        self.f = []\n",
    "        self.df = {}\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for document in self.corpus:\n",
    "            frequencies = {}\n",
    "            self.doc_len.append(len(document))\n",
    "            for word in document:\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 0\n",
    "                frequencies[word] += 1\n",
    "            self.f.append(frequencies)\n",
    "\n",
    "            for word, freq in iteritems(frequencies):\n",
    "                if word not in self.df:\n",
    "                    self.df[word] = 0\n",
    "                self.df[word] += 1\n",
    "\n",
    "        for word, freq in iteritems(self.df):\n",
    "            self.idf[word] = math.log(self.corpus_size - freq + 0.5) - math.log(freq)\n",
    "\n",
    "    def get_score(self, document, index, average_idf):\n",
    "        \"\"\"Computes BM25 score of given `document` in relation to item of corpus\n",
    "        Parameters\n",
    "        ----------\n",
    "        document : list of str\n",
    "            Document to be scored.\n",
    "        index : int\n",
    "            Index of document in corpus selected to score with `document`.\n",
    "        average_idf : float\n",
    "            Average idf in corpus.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            BM25 score.\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        for word in document:\n",
    "            if word not in self.f[index]:\n",
    "                continue\n",
    "            idf = self.idf[word] if self.idf[word] >= 0 else EPSILON * average_idf\n",
    "            score += (idf * self.f[index][word] * (PARAM_K1 + 1)) / (self.f[index][word] + \n",
    "                                                                     PARAM_K1 * (1 - PARAM_B + PARAM_B *self.doc_len[index] / self.avgdl))\n",
    "        return score\n",
    "\n",
    "    def get_scores(self, document, average_idf):\n",
    "        scores = []\n",
    "        for index in xrange(self.corpus_size):\n",
    "            score = self.get_score(document, index, average_idf)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "\n",
    "def get_bm25_weights(corpus):\n",
    "    \"\"\"Returns BM25 scores (weights) of documents in corpus.\n",
    "    Each document has to be weighted with every document in given corpus.\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : list of list of str\n",
    "        Corpus of documents.\n",
    "    Returns\n",
    "    -------\n",
    "    list of list of float\n",
    "        BM25 scores.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from gensim.summarization.bm25 import get_bm25_weights\n",
    "    >>> corpus = [\n",
    "    ...     [\"black\", \"cat\", \"white\", \"cat\"],\n",
    "    ...     [\"cat\", \"outer\", \"space\"],\n",
    "    ...     [\"wag\", \"dog\"]\n",
    "    ... ]\n",
    "    >>> result = get_bm25_weights(corpus)\n",
    "    \"\"\"\n",
    "    bm25 = BM25(corpus)\n",
    "    average_idf = sum(float(val) for val in bm25.idf.values()) / len(bm25.idf)\n",
    "\n",
    "    weights = []\n",
    "    for doc in corpus:\n",
    "        scores = bm25.get_scores(doc, average_idf)\n",
    "        weights.append(scores)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [nltk.word_tokenize(doc) for doc in norm_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_corpus_tokens = np.asarray(a, dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['rupiah', 'rawan', 'gejolak']),\n",
       "       list(['src', 'sasar', 'ritel', 'tradisional', 'jadi', 'pilar', 'ekonomi', 'nasional']),\n",
       "       list(['kiat', 'maksimal', 'facebok', 'bisnis'])], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus_tokens[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penghitungan BM25 Weights untuk Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 845 ms, sys: 20 ms, total: 865 ms\n",
      "Wall time: 865 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wts = get_bm25_weights(norm_corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1299</th>\n",
       "      <th>1300</th>\n",
       "      <th>1301</th>\n",
       "      <th>1302</th>\n",
       "      <th>1303</th>\n",
       "      <th>1304</th>\n",
       "      <th>1305</th>\n",
       "      <th>1306</th>\n",
       "      <th>1307</th>\n",
       "      <th>1308</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.60508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>40.727428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.561296</td>\n",
       "      <td>11.318120</td>\n",
       "      <td>5.423869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.318120</td>\n",
       "      <td>27.904699</td>\n",
       "      <td>5.423869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.423869</td>\n",
       "      <td>5.423869</td>\n",
       "      <td>32.020368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1          2          3          4     5     6     7     \\\n",
       "0  26.60508   0.000000   0.000000   0.000000   0.000000   0.0   0.0   0.0   \n",
       "1   0.00000  40.727428   0.000000   0.000000   0.000000   0.0   0.0   0.0   \n",
       "2   0.00000   0.000000  26.561296  11.318120   5.423869   0.0   0.0   0.0   \n",
       "3   0.00000   0.000000  11.318120  27.904699   5.423869   0.0   0.0   0.0   \n",
       "4   0.00000   0.000000   5.423869   5.423869  32.020368   0.0   0.0   0.0   \n",
       "\n",
       "   8     9     ...  1299  1300  1301  1302  1303  1304  1305  1306  1307  1308  \n",
       "0   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1309 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_wts_df = pd.DataFrame(wts)\n",
    "bm25_wts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Rupiah masih rawan bergejolak\n",
      "Top 5 recommended Articles: ['Menghadapi gejolak ekonomi global' 'Menghadapi gejolak ekonomi global'\n",
      " 'Pemanfaatan satelit untuk daerah rawan bencana'\n",
      " 'Pelemahan rupiah belum berpengaruh ke inflasi'\n",
      " 'Menjaga kurs rupiah, merawat fundamen ekonomi']\n",
      "\n",
      "Article: Kiat menambah relasi bisnis\n",
      "Top 5 recommended Articles: ['Kiat memaksimalkan Facebook untuk bisnis'\n",
      " 'Kiat memaksimalkan Facebook untuk bisnis'\n",
      " \"Kiat merintis bisnis dari ''Filosofi Kopi''\"\n",
      " 'Kiat rebranding untuk bangkitkan bisnis lesu' 'Kiat atasi FOMO']\n",
      "\n",
      "Article: Hasil imbang yang pahit bagi AC Milan\n",
      "Top 5 recommended Articles: ['AC Milan hanya butuh waktu'\n",
      " 'Mahalnya hasil imbang Milan dan laju 7 tim mapan'\n",
      " 'Kecewanya Madrid ditahan imbang Bilbao'\n",
      " 'Taktik tak berjalan, Indonesia imbang dengan Vietnam'\n",
      " 'Kekalahan Milan, kekecewaan Gattuso']\n",
      "\n",
      "Article: SRC sasar ritel tradisional jadi pilar ekonomi nasional\n",
      "Top 5 recommended Articles: ['Peran ekonomi kreatif terhadap pertumbuhan ekonomi nasional'\n",
      " 'Penerimaan zakat meningkat, perekonomian jadi target'\n",
      " 'Ketimpangan ekonomi jadi pendorong selfie seksi'\n",
      " 'Menjaring investor kecil dengan surat utang ritel'\n",
      " 'Pengusaha ritel sayangkan kurangnya koordinasi pemerintah']\n",
      "\n",
      "Article: PSM kembali ke puncak klasemen, Persib resmi tersisih\n",
      "Top 5 recommended Articles: ['Persib makin jauh dari puncak klasemen'\n",
      " 'Persija ke puncak klasemen, Persib menyerah'\n",
      " 'Persib unggul lima angka di puncak klasemen'\n",
      " 'PSM dekati puncak, Persib pilih Balikpapan' 'Persib gagal dekati PSM']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for article in popular_articles:\n",
    "    print('Article:', article)\n",
    "    print('Top 5 recommended Articles:',article_recommender(article_title=article, doc_sims=bm25_wts_df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
