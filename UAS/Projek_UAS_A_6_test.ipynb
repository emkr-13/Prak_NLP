{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UAS PMDM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "import modSpellChecker_1 as sc\n",
    "from contractions_1 import CONTRACTION_MAP\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "character = ['z','y','x','w','v','u','t','s','r','q','p','o','n','m','l','k','j','i','h','g','f','e','d',',',';',':','-','...','?','!', '(',')','[',']','{','}','<','>', '\"','/','\\'','#','-','@']\n",
    "\n",
    "def repeatcharNormalize(text):\n",
    "    for i in range(len(character)):\n",
    "        charac_long = 5\n",
    "        while charac_long >= 2:\n",
    "            char = character[i] * charac_long\n",
    "            text = text.replace(char, character[i])\n",
    "            charac_long -= 1\n",
    "    return text\n",
    "\n",
    "def spellNormalize(text):\n",
    "    spellCheck = []\n",
    "    for i in text:\n",
    "        if i not in character:\n",
    "            j = sc.correction(i)\n",
    "            spellCheck.append(j)\n",
    "        else:\n",
    "            spellCheck.append(i)\n",
    "    return spellCheck\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def expand_contractions(text, contraction_mapping):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())\n",
    "        expanded_contraction = first_char + expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "def stemmer_text(text):\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    filtered_tokens = filter(None, [pattern.sub('',token) for token in tokens])\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StopWordRemoverFactory()\n",
    "stopword_list = factory.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens = tokenize_text(text)\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, tokenize=False):\n",
    "    normalized_corpus = []\n",
    "    for text in corpus:\n",
    "        text = expand_contractions(text, CONTRACTION_MAP)\n",
    "        text = stemmer_text(text)\n",
    "        text = remove_special_characters(text)\n",
    "        text = repeatcharNormalize(text)\n",
    "        text = remove_stopwords(text)\n",
    "        normalized_corpus.append(text)\n",
    "        if tokenize:\n",
    "            text = tokenize_text(text)\n",
    "            text = spellNormalize(text)\n",
    "            normalized_corpus.append(text)\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penyiapan Data Teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Klasemen Liga Inggris: Tottenham Gusur Man Cit...</td>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>https://www.cnnindonesia.com/olahraga/20231024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Khamzat Disebut Tak Pantas Dapat Duel Gelar Ju...</td>\n",
       "      <td>Olahraga Lainnya</td>\n",
       "      <td>https://www.cnnindonesia.com/olahraga/20231023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hasil Liga Inggris: Son Cetak Gol, Tottenham H...</td>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>https://www.cnnindonesia.com/olahraga/20231024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Binder Merasa Kasihan Martin Gagal Menang di M...</td>\n",
       "      <td>Moto GP</td>\n",
       "      <td>https://www.cnnindonesia.com/olahraga/20231024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOTO: Tottenham Jaga Rekor Belum Terkalahkan U...</td>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>https://www.cnnindonesia.com/olahraga/20231024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Jadwal Siaran Langsung Final Hong Kong Open: 3...</td>\n",
       "      <td>Raket</td>\n",
       "      <td>https://www.cnnindonesia.com/olahraga/20230917...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Klasemen Liga Inggris Usai MU Terpuruk di Old ...</td>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>https://www.cnnindonesia.com/olahraga/20230917...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Ronaldo Tunjukkan Gairah Besar di Saudi Pro Le...</td>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>https://www.cnnindonesia.com/olahraga/20230917...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>2 Pemain Al Raed Berebut Tendang Penalti, Rona...</td>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>https://www.cnnindonesia.com/olahraga/20230917...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Hasil Liga Spanyol: Joao Felix Cetak Gol, Barc...</td>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>https://www.cnnindonesia.com/olahraga/20230917...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title          category  \\\n",
       "0     Klasemen Liga Inggris: Tottenham Gusur Man Cit...         Sepakbola   \n",
       "1     Khamzat Disebut Tak Pantas Dapat Duel Gelar Ju...  Olahraga Lainnya   \n",
       "2     Hasil Liga Inggris: Son Cetak Gol, Tottenham H...         Sepakbola   \n",
       "3     Binder Merasa Kasihan Martin Gagal Menang di M...           Moto GP   \n",
       "4     FOTO: Tottenham Jaga Rekor Belum Terkalahkan U...         Sepakbola   \n",
       "...                                                 ...               ...   \n",
       "1995  Jadwal Siaran Langsung Final Hong Kong Open: 3...             Raket   \n",
       "1996  Klasemen Liga Inggris Usai MU Terpuruk di Old ...         Sepakbola   \n",
       "1997  Ronaldo Tunjukkan Gairah Besar di Saudi Pro Le...         Sepakbola   \n",
       "1998  2 Pemain Al Raed Berebut Tendang Penalti, Rona...         Sepakbola   \n",
       "1999  Hasil Liga Spanyol: Joao Felix Cetak Gol, Barc...         Sepakbola   \n",
       "\n",
       "                                                   link  \n",
       "0     https://www.cnnindonesia.com/olahraga/20231024...  \n",
       "1     https://www.cnnindonesia.com/olahraga/20231023...  \n",
       "2     https://www.cnnindonesia.com/olahraga/20231024...  \n",
       "3     https://www.cnnindonesia.com/olahraga/20231024...  \n",
       "4     https://www.cnnindonesia.com/olahraga/20231024...  \n",
       "...                                                 ...  \n",
       "1995  https://www.cnnindonesia.com/olahraga/20230917...  \n",
       "1996  https://www.cnnindonesia.com/olahraga/20230917...  \n",
       "1997  https://www.cnnindonesia.com/olahraga/20230917...  \n",
       "1998  https://www.cnnindonesia.com/olahraga/20230917...  \n",
       "1999  https://www.cnnindonesia.com/olahraga/20230917...  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('cnn_sport.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dataset.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Klasemen Liga Inggris: Tottenham Gusur Man Cit...\n",
       "1    Khamzat Disebut Tak Pantas Dapat Duel Gelar Ju...\n",
       "2    Hasil Liga Inggris: Son Cetak Gol, Tottenham H...\n",
       "3    Binder Merasa Kasihan Martin Gagal Menang di M...\n",
       "4    FOTO: Tottenham Jaga Rekor Belum Terkalahkan U...\n",
       "5    INFOGRAFIS: Jadwal Timnas Indonesia di Kualifi...\n",
       "6          Messi Banggakan Capaian Bersama Inter Miami\n",
       "7    Erick Thohir Soal Persiapan Piala Dunia U-17: ...\n",
       "8    Bagnaia Mulai Pongah Jelang MotoGP Thailand da...\n",
       "9    Sidang Komdis PSSI: Hugo Samir Pukul Pemain Pe...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus = normalize_corpus(feature)\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ekstraksi Fitur dengan TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2862)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metode Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.126328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1         2     3         4     5     6     7         8     9     \\\n",
       "0  1.000000   0.0  0.196113   0.0  0.081744   0.0   0.0   0.0  0.000000   0.0   \n",
       "1  0.000000   1.0  0.000000   0.0  0.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "2  0.196113   0.0  1.000000   0.0  0.363310   0.0   0.0   0.0  0.000000   0.0   \n",
       "3  0.000000   0.0  0.000000   1.0  0.000000   0.0   0.0   0.0  0.032944   0.0   \n",
       "4  0.081744   0.0  0.363310   0.0  1.000000   0.0   0.0   0.0  0.000000   0.0   \n",
       "\n",
       "   ...      1990  1991  1992      1993  1994  1995      1996  1997  1998  \\\n",
       "0  ...  0.321987   0.0   0.0  0.000000   0.0   0.0  0.255013   0.0   0.0   \n",
       "1  ...  0.000000   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0   \n",
       "2  ...  0.219156   0.0   0.0  0.135407   0.0   0.0  0.126328   0.0   0.0   \n",
       "3  ...  0.000000   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0   \n",
       "4  ...  0.055893   0.0   0.0  0.000000   0.0   0.0  0.030026   0.0   0.0   \n",
       "\n",
       "       1999  \n",
       "0  0.028092  \n",
       "1  0.000000  \n",
       "2  0.224574  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "doc_sim_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Klasemen Liga Inggris: Tottenham Gusur Man City dari Puncak',\n",
       "        'Khamzat Disebut Tak Pantas Dapat Duel Gelar Juara UFC',\n",
       "        'Hasil Liga Inggris: Son Cetak Gol, Tottenham Hajar Fulham 2-0',\n",
       "        ...,\n",
       "        'Ronaldo Tunjukkan Gairah Besar di Saudi Pro League: Marah dan Gembira',\n",
       "        '2 Pemain Al Raed Berebut Tendang Penalti, Ronaldo Ikut Campur',\n",
       "        'Hasil Liga Spanyol: Joao Felix Cetak Gol, Barcelona Bungkam Betis 5-0'],\n",
       "       dtype=object),\n",
       " (2000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list = dataset['title'].values\n",
    "article_list, article_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_idx = np.where(article_list=='Klasemen Liga Inggris: Tottenham Gusur Man City dari Puncak')[0][0]\n",
    "article_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.19611333, ..., 0.        , 0.        ,\n",
       "       0.02809224])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_similarities = doc_sim_df.iloc[article_idx].values\n",
    "article_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  89,  845, 1476, 1212,  847, 1623, 1211, 1386,   52])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_article_idxs = np.argsort(-article_similarities)[1:10]\n",
    "similar_article_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Top 3 Sports: Tottenham Gusur Man City, Makhachev Sehebat Khabib',\n",
       "       'Klasemen Liga Inggris Usai Arsenal Gebuk Man City',\n",
       "       'Klasemen Liga Inggris: Brighton ke Tiga Besar, Arsenal Tergusur',\n",
       "       'Hasil Liga Inggris: Bantai Bournemouth, Arsenal Tempel Man City',\n",
       "       'Hasil Liga Inggris: Arsenal Benamkan Man City 1-0',\n",
       "       'Hasil Liga Inggris: 10 Pemain Man City Bekuk Nottingham 2-0',\n",
       "       'Hasil Liga Inggris: Man City dan MU Kompak Kalah',\n",
       "       'FOTO: Man City Tumbang di Piala Liga',\n",
       "       'Hasil Liga Inggris: Man City Tekuk Brighton 2-1, Haaland Cetak Gol'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_article = article_list[similar_article_idxs]\n",
    "similar_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_recommender(article_title, articles=article_list,doc_sims=doc_sim_df):\n",
    "    article_idx = np.where(articles == article_title)[0][0]\n",
    "    article_similarities = doc_sims.iloc[article_idx].values\n",
    "    similar_article_idxs = np.argsort(-article_similarities)[1:10]\n",
    "    similar_articles = articles[similar_article_idxs]\n",
    "    return similar_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_articles = ['Klasemen Liga Inggris: Tottenham Gusur Man City dari Puncak',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Klasemen Liga Inggris: Tottenham Gusur Man City dari Puncak\n",
      "Top 5 recommended Article: ['Top 3 Sports: Tottenham Gusur Man City, Makhachev Sehebat Khabib'\n",
      " 'Klasemen Liga Inggris Usai Arsenal Gebuk Man City'\n",
      " 'Klasemen Liga Inggris: Brighton ke Tiga Besar, Arsenal Tergusur'\n",
      " 'Hasil Liga Inggris: Bantai Bournemouth, Arsenal Tempel Man City'\n",
      " 'Hasil Liga Inggris: Arsenal Benamkan Man City 1-0'\n",
      " 'Hasil Liga Inggris: 10 Pemain Man City Bekuk Nottingham 2-0'\n",
      " 'Hasil Liga Inggris: Man City dan MU Kompak Kalah'\n",
      " 'FOTO: Man City Tumbang di Piala Liga'\n",
      " 'Hasil Liga Inggris: Man City Tekuk Brighton 2-1, Haaland Cetak Gol']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for article in popular_articles:\n",
    "    print('Article:', article)\n",
    "    print('Top 5 recommended Article:',article_recommender(article_title=article))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metode BM25 Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data:\n",
    "-----\n",
    ".. data:: PARAM_K1 - Free smoothing parameter for BM25.\n",
    ".. data:: PARAM_B - Free smoothing parameter for BM25.\n",
    ".. data:: EPSILON - Constant used for negative idf of document in corpus.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "from six import iteritems\n",
    "from six.moves import xrange\n",
    "\n",
    "PARAM_K1 = 2.5\n",
    "PARAM_B = 0.85\n",
    "EPSILON = 0.2\n",
    "\n",
    "class BM25(object):\n",
    "    \"\"\"Implementation of Best Matching 25 ranking function.\n",
    "    Attributes\n",
    "    ----------\n",
    "    corpus_size : int\n",
    "        Size of corpus (number of documents).\n",
    "    avgdl : float\n",
    "        Average length of document in `corpus`.\n",
    "    corpus : list of list of str\n",
    "        Corpus of documents.\n",
    "    f : list of dicts of int\n",
    "        Dictionary with terms frequencies for each document in `corpus`.\n",
    "    df : dict\n",
    "        Dictionary with terms frequencies for whole `corpus`.\n",
    "    idf : dict\n",
    "        Dictionary with inversed terms frequencies for while `corpus`.\n",
    "    doc_len : list of int\n",
    "        List of document lengths.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, corpus):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus : list of list of str\n",
    "            Given corpus.\n",
    "        \"\"\"\n",
    "        self.corpus_size = len(corpus)\n",
    "        self.avgdl = sum(float(len(x)) for x in corpus) / self.corpus_size\n",
    "        self.corpus = corpus\n",
    "        self.f = []\n",
    "        self.df = {}\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for document in self.corpus:\n",
    "            frequencies = {}\n",
    "            self.doc_len.append(len(document))\n",
    "            for word in document:\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 0\n",
    "                frequencies[word] += 1\n",
    "            self.f.append(frequencies)\n",
    "\n",
    "            for word, freq in iteritems(frequencies):\n",
    "                if word not in self.df:\n",
    "                    self.df[word] = 0\n",
    "                self.df[word] += 1\n",
    "\n",
    "        for word, freq in iteritems(self.df):\n",
    "            self.idf[word] = math.log(self.corpus_size - freq + 0.5) - math.log(freq)\n",
    "\n",
    "    def get_score(self, document, index, average_idf):\n",
    "        \"\"\"Computes BM25 score of given `document` in relation to item of corpus\n",
    "        Parameters\n",
    "        ----------\n",
    "        document : list of str\n",
    "            Document to be scored.\n",
    "        index : int\n",
    "            Index of document in corpus selected to score with `document`.\n",
    "        average_idf : float\n",
    "            Average idf in corpus.\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            BM25 score.\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        for word in document:\n",
    "            if word not in self.f[index]:\n",
    "                continue\n",
    "            idf = self.idf[word] if self.idf[word] >= 0 else EPSILON * average_idf\n",
    "            score += (idf * self.f[index][word] * (PARAM_K1 + 1)) / (self.f[index][word] + \n",
    "                                                                     PARAM_K1 * (1 - PARAM_B + PARAM_B *self.doc_len[index] / self.avgdl))\n",
    "        return score\n",
    "\n",
    "    def get_scores(self, document, average_idf):\n",
    "        scores = []\n",
    "        for index in xrange(self.corpus_size):\n",
    "            score = self.get_score(document, index, average_idf)\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "\n",
    "def get_bm25_weights(corpus):\n",
    "    \"\"\"Returns BM25 scores (weights) of documents in corpus.\n",
    "    Each document has to be weighted with every document in given corpus.\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : list of list of str\n",
    "        Corpus of documents.\n",
    "    Returns\n",
    "    -------\n",
    "    list of list of float\n",
    "        BM25 scores.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from gensim.summarization.bm25 import get_bm25_weights\n",
    "    >>> corpus = [\n",
    "    ...     [\"black\", \"cat\", \"white\", \"cat\"],\n",
    "    ...     [\"cat\", \"outer\", \"space\"],\n",
    "    ...     [\"wag\", \"dog\"]\n",
    "    ... ]\n",
    "    >>> result = get_bm25_weights(corpus)\n",
    "    \"\"\"\n",
    "    bm25 = BM25(corpus)\n",
    "    average_idf = sum(float(val) for val in bm25.idf.values()) / len(bm25.idf)\n",
    "\n",
    "    weights = []\n",
    "    for doc in corpus:\n",
    "        scores = bm25.get_scores(doc, average_idf)\n",
    "        weights.append(scores)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [nltk.word_tokenize(doc) for doc in norm_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_corpus_tokens = np.asarray(a, dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['klasemen', 'liga', 'ingris', 'totenham', 'gusur', 'man', 'city', 'puncak']),\n",
       "       list(['khamzat', 'sebut', 'tak', 'pantas', 'duel', 'gelar', 'juara', 'ufc']),\n",
       "       list(['hasil', 'liga', 'ingris', 'son', 'cetak', 'gol', 'totenham', 'hajar', 'fulham', '20'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus_tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.96 s, sys: 36 ms, total: 3 s\n",
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wts = get_bm25_weights(norm_corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.876276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.826123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.986329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.654752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.533070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.016136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.861775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.284396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.953930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.521029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.209499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.778618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.298067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.492777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.320898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.094916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.986329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.515259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.906775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.360153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.464951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1          2          3          4     5     6     7     \\\n",
       "0  34.876276   0.000000   9.826123   0.000000   4.986329   0.0   0.0   0.0   \n",
       "1   0.000000  39.861775   0.000000   0.000000   0.000000   0.0   0.0   0.0   \n",
       "2  11.284396   0.000000  36.953930   0.000000  15.521029   0.0   0.0   0.0   \n",
       "3   0.000000   0.000000   0.000000  36.320898   0.000000   0.0   0.0   0.0   \n",
       "4   4.986329   0.000000  13.515259   0.000000  35.906775   0.0   0.0   0.0   \n",
       "\n",
       "       8     9     ...       1990  1991  1992      1993  1994  1995      1996  \\\n",
       "0  0.000000   0.0  ...  12.654752   0.0   0.0  0.000000   0.0   0.0  9.533070   \n",
       "1  0.000000   0.0  ...   0.000000   0.0   0.0  0.000000   0.0   0.0  0.000000   \n",
       "2  0.000000   0.0  ...  10.209499   0.0   0.0  5.778618   0.0   0.0  6.298067   \n",
       "3  2.094916   0.0  ...   0.000000   0.0   0.0  0.000000   0.0   0.0  0.000000   \n",
       "4  0.000000   0.0  ...   3.360153   0.0   0.0  0.000000   0.0   0.0  2.464951   \n",
       "\n",
       "   1997  1998      1999  \n",
       "0   0.0   0.0  2.016136  \n",
       "1   0.0   0.0  0.000000  \n",
       "2   0.0   0.0  9.492777  \n",
       "3   0.0   0.0  0.000000  \n",
       "4   0.0   0.0  0.000000  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_wts_df = pd.DataFrame(wts)\n",
    "bm25_wts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Klasemen Liga Inggris: Tottenham Gusur Man City dari Puncak\n",
      "Top 5 recommended Articles: ['Klasemen Liga Inggris Usai Arsenal Gebuk Man City'\n",
      " 'Top 3 Sports: Tottenham Gusur Man City, Makhachev Sehebat Khabib'\n",
      " 'Hasil Liga Inggris: Man City dan MU Kompak Kalah'\n",
      " 'Hasil Liga Inggris: Arsenal Benamkan Man City 1-0'\n",
      " 'Klasemen Liga Inggris: Brighton ke Tiga Besar, Arsenal Tergusur']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for article in popular_articles:\n",
    "    print('Article:', article)\n",
    "    print('Top 5 recommended Articles:',article_recommender(article_title=article, doc_sims=bm25_wts_df))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
